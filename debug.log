Seed 0
Start loading data
Splitting dataset with Seed = 0.
Dataset size: 555    Train size: 444    Val size: 55    Test size: 56
Training Model
FpgnnModel(
  (sigmoid): Sigmoid()
  (encoder3): GAT(
    (encoder): GATEncoder(
      (encoder): GATOne(
        (dropout): Dropout(p=0.0, inplace=False)
        (attention_0): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (attention_1): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (out_att): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
      )
    )
  )
  (encoder2): FPN(
    (fc1): Linear(in_features=1489, out_features=550, bias=True)
    (act_func): ReLU()
    (fc2): Linear(in_features=550, out_features=300, bias=True)
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (fc_gat): Linear(in_features=300, out_features=360, bias=True)
  (fc_fpn): Linear(in_features=300, out_features=240, bias=True)
  (act_func): ReLU()
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Epoch 0
Train f1 = 0.000000
Validation f1 = 0.000000
Epoch 1
Train f1 = 0.000000
Validation f1 = 0.000000
Epoch 2
Train f1 = 0.455172
Validation f1 = 0.666667
Epoch 3
Train f1 = 0.400000
Validation f1 = 0.571429
Epoch 4
Train f1 = 0.638298
Validation f1 = 0.666667
Epoch 5
Train f1 = 0.560976
Validation f1 = 0.615385
Epoch 6
Train f1 = 0.750000
Validation f1 = 0.615385
Epoch 7
Train f1 = 0.864865
Validation f1 = 0.714286
Epoch 8
Train f1 = 0.885246
Validation f1 = 0.761905
Epoch 9
Train f1 = 0.896552
Validation f1 = 0.736842
Epoch 10
Train f1 = 0.888889
Validation f1 = 0.588235
Epoch 11
Train f1 = 0.934426
Validation f1 = 0.800000
Epoch 12
Train f1 = 0.936937
Validation f1 = 0.500000
Epoch 13
Train f1 = 0.958678
Validation f1 = 0.800000
Epoch 14
Train f1 = 0.973913
Validation f1 = 0.666667
Epoch 15
Train f1 = 0.983051
Validation f1 = 0.736842
Epoch 16
Train f1 = 0.974359
Validation f1 = 0.666667
Epoch 17
Train f1 = 0.957983
Validation f1 = 0.736842
Epoch 18
Train f1 = 0.982759
Validation f1 = 0.588235
Epoch 19
Train f1 = 0.982759
Validation f1 = 0.666667
Epoch 20
Train f1 = 0.982759
Validation f1 = 0.666667
Epoch 21
Train f1 = 0.974790
Validation f1 = 0.736842
Epoch 22
Train f1 = 0.982759
Validation f1 = 0.666667
Epoch 23
Train f1 = 0.982456
Validation f1 = 0.666667
Epoch 24
Train f1 = 0.982759
Validation f1 = 0.736842
Epoch 25
Train f1 = 0.982759
Validation f1 = 0.666667
Epoch 26
Train f1 = 0.982456
Validation f1 = 0.666667
Epoch 27
Train f1 = 0.982456
Validation f1 = 0.705882
Epoch 28
Train f1 = 0.982456
Validation f1 = 0.666667
Epoch 29
Train f1 = 0.982456
Validation f1 = 0.736842
Best validation f1 = 0.800000 on epoch 11
Load parameter: encoder3.encoder.encoder.attention_0.W.
Load parameter: encoder3.encoder.encoder.attention_0.a.
Load parameter: encoder3.encoder.encoder.attention_1.W.
Load parameter: encoder3.encoder.encoder.attention_1.a.
Load parameter: encoder3.encoder.encoder.out_att.W.
Load parameter: encoder3.encoder.encoder.out_att.a.
Load parameter: encoder2.fc1.weight.
Load parameter: encoder2.fc1.bias.
Load parameter: encoder2.fc2.weight.
Load parameter: encoder2.fc2.bias.
Load parameter: fc_gat.weight.
Load parameter: fc_gat.bias.
Load parameter: fc_fpn.weight.
Load parameter: fc_fpn.bias.
Load parameter: ffn.1.weight.
Load parameter: ffn.1.bias.
Load parameter: ffn.4.weight.
Load parameter: ffn.4.bias.
Seed 0 : test f1 = 0.666667
Seed 0
Start loading data
Splitting dataset with Seed = 1.
Dataset size: 555    Train size: 444    Val size: 55    Test size: 56
Training Model
FpgnnModel(
  (sigmoid): Sigmoid()
  (encoder3): GAT(
    (encoder): GATEncoder(
      (encoder): GATOne(
        (dropout): Dropout(p=0.0, inplace=False)
        (attention_0): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (attention_1): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (out_att): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
      )
    )
  )
  (encoder2): FPN(
    (fc1): Linear(in_features=1489, out_features=550, bias=True)
    (act_func): ReLU()
    (fc2): Linear(in_features=550, out_features=300, bias=True)
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (fc_gat): Linear(in_features=300, out_features=360, bias=True)
  (fc_fpn): Linear(in_features=300, out_features=240, bias=True)
  (act_func): ReLU()
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Epoch 0
Train f1 = 0.032258
Validation f1 = 0.000000
Epoch 1
Train f1 = 0.428571
Validation f1 = 0.666667
Epoch 2
Train f1 = 0.457831
Validation f1 = 0.500000
Epoch 3
Train f1 = 0.754717
Validation f1 = 0.545455
Epoch 4
Train f1 = 0.754386
Validation f1 = 0.666667
Epoch 5
Train f1 = 0.890909
Validation f1 = 0.666667
Epoch 6
Train f1 = 0.708333
Validation f1 = 0.666667
Epoch 7
Train f1 = 0.857143
Validation f1 = 0.750000
Epoch 8
Train f1 = 0.939130
Validation f1 = 0.727273
Epoch 9
Train f1 = 0.966102
Validation f1 = 0.727273
Epoch 10
Train f1 = 0.991597
Validation f1 = 0.666667
Epoch 11
Train f1 = 0.991597
Validation f1 = 0.615385
Epoch 12
Train f1 = 0.983051
Validation f1 = 0.666667
Epoch 13
Train f1 = 0.991736
Validation f1 = 0.500000
Epoch 14
Train f1 = 0.991597
Validation f1 = 0.727273
Epoch 15
Train f1 = 0.991597
Validation f1 = 0.727273
Epoch 16
Train f1 = 1.000000
Validation f1 = 0.571429
Epoch 17
Train f1 = 1.000000
Validation f1 = 0.666667
Epoch 18
Train f1 = 1.000000
Validation f1 = 0.800000
Epoch 19
Train f1 = 1.000000
Validation f1 = 0.500000
Epoch 20
Train f1 = 1.000000
Validation f1 = 0.800000
Epoch 21
Train f1 = 1.000000
Validation f1 = 0.800000
Epoch 22
Train f1 = 1.000000
Validation f1 = 0.500000
Epoch 23
Train f1 = 1.000000
Validation f1 = 0.727273
Epoch 24
Train f1 = 1.000000
Validation f1 = 0.800000
Epoch 25
Train f1 = 1.000000
Validation f1 = 0.800000
Epoch 26
Train f1 = 1.000000
Validation f1 = 0.727273
Epoch 27
Train f1 = 1.000000
Validation f1 = 0.727273
Epoch 28
Train f1 = 1.000000
Validation f1 = 0.727273
Epoch 29
Train f1 = 1.000000
Validation f1 = 0.727273
Best validation f1 = 0.800000 on epoch 18
Load parameter: encoder3.encoder.encoder.attention_0.W.
Load parameter: encoder3.encoder.encoder.attention_0.a.
Load parameter: encoder3.encoder.encoder.attention_1.W.
Load parameter: encoder3.encoder.encoder.attention_1.a.
Load parameter: encoder3.encoder.encoder.out_att.W.
Load parameter: encoder3.encoder.encoder.out_att.a.
Load parameter: encoder2.fc1.weight.
Load parameter: encoder2.fc1.bias.
Load parameter: encoder2.fc2.weight.
Load parameter: encoder2.fc2.bias.
Load parameter: fc_gat.weight.
Load parameter: fc_gat.bias.
Load parameter: fc_fpn.weight.
Load parameter: fc_fpn.bias.
Load parameter: ffn.1.weight.
Load parameter: ffn.1.bias.
Load parameter: ffn.4.weight.
Load parameter: ffn.4.bias.
Seed 1 : test f1 = 0.533333
Seed 1
Start loading data
Splitting dataset with Seed = 2.
Dataset size: 555    Train size: 444    Val size: 55    Test size: 56
Training Model
FpgnnModel(
  (sigmoid): Sigmoid()
  (encoder3): GAT(
    (encoder): GATEncoder(
      (encoder): GATOne(
        (dropout): Dropout(p=0.0, inplace=False)
        (attention_0): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (attention_1): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (out_att): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
      )
    )
  )
  (encoder2): FPN(
    (fc1): Linear(in_features=1489, out_features=550, bias=True)
    (act_func): ReLU()
    (fc2): Linear(in_features=550, out_features=300, bias=True)
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (fc_gat): Linear(in_features=300, out_features=360, bias=True)
  (fc_fpn): Linear(in_features=300, out_features=240, bias=True)
  (act_func): ReLU()
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Epoch 0
Train f1 = 0.238806
Validation f1 = 0.000000
Epoch 1
Train f1 = 0.469388
Validation f1 = 0.000000
Epoch 2
Train f1 = 0.467532
Validation f1 = 0.000000
Epoch 3
Train f1 = 0.578313
Validation f1 = 0.000000
Epoch 4
Train f1 = 0.629213
Validation f1 = 0.000000
Epoch 5
Train f1 = 0.447368
Validation f1 = 0.000000
Epoch 6
Train f1 = 0.808081
Validation f1 = 0.222222
Epoch 7
Train f1 = 0.859813
Validation f1 = 0.222222
Epoch 8
Train f1 = 0.852941
Validation f1 = 0.222222
Epoch 9
Train f1 = 0.925926
Validation f1 = 0.222222
Epoch 10
Train f1 = 0.941176
Validation f1 = 0.363636
Epoch 11
Train f1 = 0.950820
Validation f1 = 0.461538
Epoch 12
Train f1 = 0.966102
Validation f1 = 0.400000
Epoch 13
Train f1 = 0.974790
Validation f1 = 0.400000
Epoch 14
Train f1 = 0.974359
Validation f1 = 0.400000
Epoch 15
Train f1 = 0.973913
Validation f1 = 0.363636
Epoch 16
Train f1 = 0.982759
Validation f1 = 0.400000
Epoch 17
Train f1 = 0.982759
Validation f1 = 0.400000
Epoch 18
Train f1 = 0.966667
Validation f1 = 0.545455
Epoch 19
Train f1 = 0.983051
Validation f1 = 0.400000
Epoch 20
Train f1 = 0.964286
Validation f1 = 0.222222
Epoch 21
Train f1 = 0.983051
Validation f1 = 0.400000
Epoch 22
Train f1 = 0.983051
Validation f1 = 0.400000
Epoch 23
Train f1 = 0.983051
Validation f1 = 0.400000
Epoch 24
Train f1 = 0.982456
Validation f1 = 0.400000
Epoch 25
Train f1 = 0.983051
Validation f1 = 0.400000
Epoch 26
Train f1 = 0.982759
Validation f1 = 0.400000
Epoch 27
Train f1 = 0.982759
Validation f1 = 0.400000
Epoch 28
Train f1 = 0.982759
Validation f1 = 0.400000
Epoch 29
Train f1 = 0.983051
Validation f1 = 0.400000
Best validation f1 = 0.545455 on epoch 18
Load parameter: encoder3.encoder.encoder.attention_0.W.
Load parameter: encoder3.encoder.encoder.attention_0.a.
Load parameter: encoder3.encoder.encoder.attention_1.W.
Load parameter: encoder3.encoder.encoder.attention_1.a.
Load parameter: encoder3.encoder.encoder.out_att.W.
Load parameter: encoder3.encoder.encoder.out_att.a.
Load parameter: encoder2.fc1.weight.
Load parameter: encoder2.fc1.bias.
Load parameter: encoder2.fc2.weight.
Load parameter: encoder2.fc2.bias.
Load parameter: fc_gat.weight.
Load parameter: fc_gat.bias.
Load parameter: fc_fpn.weight.
Load parameter: fc_fpn.bias.
Load parameter: ffn.1.weight.
Load parameter: ffn.1.bias.
Load parameter: ffn.4.weight.
Load parameter: ffn.4.bias.
Seed 2 : test f1 = 0.857143
Seed 2
Start loading data
Splitting dataset with Seed = 3.
Dataset size: 555    Train size: 444    Val size: 55    Test size: 56
Training Model
FpgnnModel(
  (sigmoid): Sigmoid()
  (encoder3): GAT(
    (encoder): GATEncoder(
      (encoder): GATOne(
        (dropout): Dropout(p=0.0, inplace=False)
        (attention_0): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (attention_1): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (out_att): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
      )
    )
  )
  (encoder2): FPN(
    (fc1): Linear(in_features=1489, out_features=550, bias=True)
    (act_func): ReLU()
    (fc2): Linear(in_features=550, out_features=300, bias=True)
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (fc_gat): Linear(in_features=300, out_features=360, bias=True)
  (fc_fpn): Linear(in_features=300, out_features=240, bias=True)
  (act_func): ReLU()
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Epoch 0
Train f1 = 0.365591
Validation f1 = 0.285714
Epoch 1
Train f1 = 0.400000
Validation f1 = 0.285714
Epoch 2
Train f1 = 0.302326
Validation f1 = 0.000000
Epoch 3
Train f1 = 0.380952
Validation f1 = 0.285714
Epoch 4
Train f1 = 0.395062
Validation f1 = 0.000000
Epoch 5
Train f1 = 0.777778
Validation f1 = 0.285714
Epoch 6
Train f1 = 0.776316
Validation f1 = 0.181818
Epoch 7
Train f1 = 0.869565
Validation f1 = 0.285714
Epoch 8
Train f1 = 0.929134
Validation f1 = 0.285714
Epoch 9
Train f1 = 0.836364
Validation f1 = 0.285714
Epoch 10
Train f1 = 0.961832
Validation f1 = 0.250000
Epoch 11
Train f1 = 0.920863
Validation f1 = 0.200000
Epoch 12
Train f1 = 0.968750
Validation f1 = 0.285714
Epoch 13
Train f1 = 0.977099
Validation f1 = 0.285714
Epoch 14
Train f1 = 0.977099
Validation f1 = 0.250000
Epoch 15
Train f1 = 0.977099
Validation f1 = 0.285714
Epoch 16
Train f1 = 0.984375
Validation f1 = 0.285714
Epoch 17
Train f1 = 0.977099
Validation f1 = 0.250000
Epoch 18
Train f1 = 0.984375
Validation f1 = 0.285714
Epoch 19
Train f1 = 0.984615
Validation f1 = 0.250000
Epoch 20
Train f1 = 0.984375
Validation f1 = 0.285714
Epoch 21
Train f1 = 0.984615
Validation f1 = 0.222222
Epoch 22
Train f1 = 0.992126
Validation f1 = 0.285714
Epoch 23
Train f1 = 0.992126
Validation f1 = 0.285714
Epoch 24
Train f1 = 0.992248
Validation f1 = 0.250000
Epoch 25
Train f1 = 0.992248
Validation f1 = 0.250000
Epoch 26
Train f1 = 0.992248
Validation f1 = 0.285714
Epoch 27
Train f1 = 0.992248
Validation f1 = 0.285714
Epoch 28
Train f1 = 0.992248
Validation f1 = 0.285714
Epoch 29
Train f1 = 0.992126
Validation f1 = 0.285714
Best validation f1 = 0.285714 on epoch 0
Load parameter: encoder3.encoder.encoder.attention_0.W.
Load parameter: encoder3.encoder.encoder.attention_0.a.
Load parameter: encoder3.encoder.encoder.attention_1.W.
Load parameter: encoder3.encoder.encoder.attention_1.a.
Load parameter: encoder3.encoder.encoder.out_att.W.
Load parameter: encoder3.encoder.encoder.out_att.a.
Load parameter: encoder2.fc1.weight.
Load parameter: encoder2.fc1.bias.
Load parameter: encoder2.fc2.weight.
Load parameter: encoder2.fc2.bias.
Load parameter: fc_gat.weight.
Load parameter: fc_gat.bias.
Load parameter: fc_fpn.weight.
Load parameter: fc_fpn.bias.
Load parameter: ffn.1.weight.
Load parameter: ffn.1.bias.
Load parameter: ffn.4.weight.
Load parameter: ffn.4.bias.
Seed 3 : test f1 = 0.000000
Seed 3
Start loading data
Splitting dataset with Seed = 4.
Dataset size: 555    Train size: 444    Val size: 55    Test size: 56
Training Model
FpgnnModel(
  (sigmoid): Sigmoid()
  (encoder3): GAT(
    (encoder): GATEncoder(
      (encoder): GATOne(
        (dropout): Dropout(p=0.0, inplace=False)
        (attention_0): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (attention_1): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
        (out_att): GATLayer(
          (dropout): Dropout(p=0.0, inplace=False)
          (leakyrelu): LeakyReLU(negative_slope=0.2)
        )
      )
    )
  )
  (encoder2): FPN(
    (fc1): Linear(in_features=1489, out_features=550, bias=True)
    (act_func): ReLU()
    (fc2): Linear(in_features=550, out_features=300, bias=True)
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (fc_gat): Linear(in_features=300, out_features=360, bias=True)
  (fc_fpn): Linear(in_features=300, out_features=240, bias=True)
  (act_func): ReLU()
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Epoch 0
Train f1 = 0.000000
Validation f1 = 0.000000
Epoch 1
Train f1 = 0.000000
Validation f1 = 0.000000
Epoch 2
Train f1 = 0.029412
Validation f1 = 0.000000
Epoch 3
Train f1 = 0.376471
Validation f1 = 0.285714
Epoch 4
Train f1 = 0.300000
Validation f1 = 0.285714
Epoch 5
Train f1 = 0.702703
Validation f1 = 0.500000
Epoch 6
Train f1 = 0.838235
Validation f1 = 0.615385
Epoch 7
Train f1 = 0.887324
Validation f1 = 0.571429
Epoch 8
Train f1 = 0.940299
Validation f1 = 0.615385
Epoch 9
Train f1 = 0.962406
Validation f1 = 0.615385
Epoch 10
Train f1 = 0.970588
Validation f1 = 0.615385
Epoch 11
Train f1 = 0.969231
Validation f1 = 0.666667
Epoch 12
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 13
Train f1 = 0.985294
Validation f1 = 0.615385
Epoch 14
Train f1 = 0.992593
Validation f1 = 0.615385
Epoch 15
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 16
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 17
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 18
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 19
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 20
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 21
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 22
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 23
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 24
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 25
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 26
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 27
Train f1 = 1.000000
Validation f1 = 0.615385
Epoch 28
Train f1 = 1.000000
Validation f1 = 0.666667
Epoch 29
Train f1 = 1.000000
Validation f1 = 0.666667
Best validation f1 = 0.666667 on epoch 11
Load parameter: encoder3.encoder.encoder.attention_0.W.
Load parameter: encoder3.encoder.encoder.attention_0.a.
Load parameter: encoder3.encoder.encoder.attention_1.W.
Load parameter: encoder3.encoder.encoder.attention_1.a.
Load parameter: encoder3.encoder.encoder.out_att.W.
Load parameter: encoder3.encoder.encoder.out_att.a.
Load parameter: encoder2.fc1.weight.
Load parameter: encoder2.fc1.bias.
Load parameter: encoder2.fc2.weight.
Load parameter: encoder2.fc2.bias.
Load parameter: fc_gat.weight.
Load parameter: fc_gat.bias.
Load parameter: fc_fpn.weight.
Load parameter: fc_fpn.bias.
Load parameter: ffn.1.weight.
Load parameter: ffn.1.bias.
Load parameter: ffn.4.weight.
Load parameter: ffn.4.bias.
Seed 4 : test f1 = 0.000000
Running 5 folds in total.
Seed 0 : test f1 = 0.666667
Seed 1 : test f1 = 0.533333
Seed 2 : test f1 = 0.857143
Seed 3 : test f1 = 0.000000
Seed 4 : test f1 = 0.000000
Average test f1 = 0.411429 +/- 0.351345
Seed 0
Start loading data
Seed 0
Start loading data
